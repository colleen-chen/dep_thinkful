{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "import time\n",
    "import sys\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project\n",
    "\n",
    "Data cleaning / processing / language parsing\n",
    "\n",
    "Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "\n",
    "Use the features to fit supervised learning models for each feature set to predict the \n",
    "category outcomes.\n",
    "\n",
    "Assess your models using cross-validation and determine whether one model performed better.\n",
    "\n",
    "Pick one of the models and try to increase accuracy by at least 5 percentage points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_start_time(t = dt.now):\n",
    "    print('start time {}'.format(t))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_end_time(starttime, t = dt.now):\n",
    "    print('end time {}'.format(t))\n",
    "    print('Total time passed is {}'.format(t - starttime))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies(x, include_stop=True):\n",
    "    words = []\n",
    "    for token in x:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            words.append(token.text)\n",
    "            \n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_frequencies(text, include_stop=True):\n",
    "    lemmas = []\n",
    "    for token in text:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    return Counter(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(x):\n",
    "    x = re.sub(r'--', ' ', x)\n",
    "    x = re.sub(r'\\*+', ' ', x)\n",
    "    x = re.sub(\"[\\[].*?[\\]]\", \"\", x)\n",
    "    x = ' '.join(x.split())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text, nsize, include_stop):\n",
    "    container = lemma_frequencies(text, include_stop).most_common(nsize)\n",
    "    return [item[0] for item in container]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_of_features(sentences, common_words):\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "    \n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print('Processing row {}'.format(i))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_words_per_sentence(sentences, df):\n",
    "    words = []\n",
    "    for ss in sentences[0]:\n",
    "        words.append(len(ss)) \n",
    "        \n",
    "    df_local = pd.DataFrame(words, columns=['entity'])\n",
    "    df['count'] = df_local.describe().loc['count', 'entity']\n",
    "    df['25perc'] = df_local.describe().loc['25%', 'entity']\n",
    "    df['50perc'] = df_local.describe().loc['50%', 'entity']\n",
    "    df['75perc'] = df_local.describe().loc['75%', 'entity']\n",
    "    df['max'] = df_local.describe().loc['max', 'entity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_of_features(sentences, common_words):\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    # tf-idf\n",
    "    for w in common_words:\n",
    "        df[w + '-tfidf'] = 0\n",
    "    \n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "    \n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        for w in words:\n",
    "            tf = df.loc[i, w]\n",
    "            idf = math.log2(1/tf) if tf != 0 else 0\n",
    "            col = w + '-tfidf'\n",
    "            df.loc[i, col] = tf * idf \n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print('Processing row {}'.format(i))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "# Grab and Process the raw data\n",
    "print(gutenberg.fileids())\n",
    "\n",
    "chesterton = gutenberg.raw('chesterton-brown.txt')\n",
    "austen = gutenberg.raw('austen-persuasion.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning Data\n",
    "# removing Chapter\n",
    "chesterton = re.sub(r'[I]*[V]*[X]*\\. ', '', chesterton)\n",
    "austen = re.sub(r'Chapter \\d+', '', austen)\n",
    "chesterton = text_cleaner(chesterton)\n",
    "austen = text_cleaner(austen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "chesterton_doc = nlp(chesterton)\n",
    "austen_doc = nlp(austen)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(The, Absence, of, Mr, Glass, THE, consulting,...</td>\n",
       "      <td>chesterton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(In, such, a, place, the, sea, had, something,...</td>\n",
       "      <td>chesterton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(It, must, not, be, supposed, that, Dr, Hood, ...</td>\n",
       "      <td>chesterton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0           1\n",
       "0  (The, Absence, of, Mr, Glass, THE, consulting,...  chesterton\n",
       "1  (In, such, a, place, the, sea, had, something,...  chesterton\n",
       "2  (It, must, not, be, supposed, that, Dr, Hood, ...  chesterton"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group into sentences\n",
    "chesterton_sent = [[sent, 'chesterton'] for sent in chesterton_doc.sents]\n",
    "austen_sent = [[sent, 'austen'] for sent in austen_doc.sents]\n",
    "sentences = pd.DataFrame(chesterton_sent + austen_sent)\n",
    "sentences.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use bag_of_words modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing common_words\n",
    "chesterton_common = bag_of_words(chesterton_doc, 40, False)\n",
    "austen_common = bag_of_words(austen_doc, 40, False)\n",
    "\n",
    "words_common = [x for x in (set(chesterton_common) - set(austen_common))]\n",
    "for y in (set(austen_common) - set(chesterton_common)):\n",
    "    words_common.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n",
      "Processing row 5500\n",
      "Processing row 6000\n",
      "Processing row 6500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priest</th>\n",
       "      <th>face</th>\n",
       "      <th>long</th>\n",
       "      <th>flambeau</th>\n",
       "      <th>brown</th>\n",
       "      <th>tell</th>\n",
       "      <th>old</th>\n",
       "      <th>and</th>\n",
       "      <th>door</th>\n",
       "      <th>be</th>\n",
       "      <th>...</th>\n",
       "      <th>good</th>\n",
       "      <th>musgrove</th>\n",
       "      <th>mary</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>count</th>\n",
       "      <th>25perc</th>\n",
       "      <th>50perc</th>\n",
       "      <th>75perc</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, Absence, of, Mr, Glass, THE, consulting,...</td>\n",
       "      <td>chesterton</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(In, such, a, place, the, sea, had, something,...</td>\n",
       "      <td>chesterton</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(It, must, not, be, supposed, that, Dr, Hood, ...</td>\n",
       "      <td>chesterton</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  priest face long flambeau brown tell old and door be  ...   good musgrove  \\\n",
       "0      0    0    0        0     0    0   0   0    0  0  ...      0        0   \n",
       "1      0    0    0        0     0    0   0   0    0  0  ...      0        0   \n",
       "2      0    0    0        0     0    0   0   0    0  0  ...      0        0   \n",
       "\n",
       "  mary                                      text_sentence text_source   count  \\\n",
       "0    0  (The, Absence, of, Mr, Glass, THE, consulting,...  chesterton  6590.0   \n",
       "1    0  (In, such, a, place, the, sea, had, something,...  chesterton  6590.0   \n",
       "2    0  (It, must, not, be, supposed, that, Dr, Hood, ...  chesterton  6590.0   \n",
       "\n",
       "  25perc 50perc 75perc    max  \n",
       "0   12.0   21.0   36.0  227.0  \n",
       "1   12.0   21.0   36.0  227.0  \n",
       "2   12.0   21.0   36.0  227.0  \n",
       "\n",
       "[3 rows x 51 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constructing Dataset\n",
    "features = bow_of_features(sentences, words_common)\n",
    "# add words per sentence statistics\n",
    "stat_words_per_sentence(sentences, features)\n",
    "features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score : 0.7935919055649241\n",
      "Test set score : 0.7627586206896552\n"
     ]
    }
   ],
   "source": [
    "Y = features['text_source']\n",
    "X = features.drop(['text_source', 'text_sentence'], 1)\n",
    "\n",
    "# RandomForestModel\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,\n",
    "                                                    Y,\n",
    "                                                    test_size=0.55,\n",
    "                                                    random_state=4)\n",
    "rfc.fit(X_train, Y_train)\n",
    "\n",
    "print('Training set score : {}'.format(rfc.score(X_train, Y_train)))\n",
    "print('Test set score : {}'.format(rfc.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73584906, 0.76518219, 0.76653171, 0.76653171])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, X_train, Y_train, cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logical Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score : 0.7672849915682968\n",
      "Test set score : 0.7671724137931034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.74528302, 0.76518219, 0.76518219, 0.76923077])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "print('Training set score : {}'.format(lr.score(X_train, Y_train)))\n",
    "print('Test set score : {}'.format(lr.score(X_test, Y_test)))\n",
    "cross_val_score(lr, X_train, Y_train, cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd approach, using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 1000\n",
      "Processing row 2000\n",
      "Processing row 3000\n",
      "Processing row 4000\n",
      "Processing row 5000\n",
      "Processing row 6000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priest</th>\n",
       "      <th>face</th>\n",
       "      <th>long</th>\n",
       "      <th>flambeau</th>\n",
       "      <th>brown</th>\n",
       "      <th>tell</th>\n",
       "      <th>old</th>\n",
       "      <th>and</th>\n",
       "      <th>door</th>\n",
       "      <th>be</th>\n",
       "      <th>...</th>\n",
       "      <th>miss-tfidf</th>\n",
       "      <th>wentworth-tfidf</th>\n",
       "      <th>good-tfidf</th>\n",
       "      <th>musgrove-tfidf</th>\n",
       "      <th>mary-tfidf</th>\n",
       "      <th>count</th>\n",
       "      <th>25perc</th>\n",
       "      <th>50perc</th>\n",
       "      <th>75perc</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   priest  face  long  flambeau  brown  tell  old  and  door  be  ...    \\\n",
       "0       0     0     0         0      0     0    0    0     0   0  ...     \n",
       "1       0     0     0         0      0     0    0    0     0   0  ...     \n",
       "2       0     0     0         0      0     0    0    0     0   0  ...     \n",
       "3       0     0     0         0      0     0    0    0     0   0  ...     \n",
       "4       0     0     0         0      0     0    0    0     0   0  ...     \n",
       "5       0     0     0         0      0     0    0    0     0   0  ...     \n",
       "6       0     0     0         0      0     0    0    0     0   0  ...     \n",
       "7       0     0     0         0      0     0    1    0     0   0  ...     \n",
       "8       0     0     0         0      0     0    0    0     0   0  ...     \n",
       "9       0     0     0         0      0     0    0    1     0   0  ...     \n",
       "\n",
       "   miss-tfidf  wentworth-tfidf  good-tfidf  musgrove-tfidf  mary-tfidf  \\\n",
       "0         0.0              0.0         0.0             0.0         0.0   \n",
       "1         0.0              0.0         0.0             0.0         0.0   \n",
       "2         0.0              0.0         0.0             0.0         0.0   \n",
       "3         0.0              0.0         0.0             0.0         0.0   \n",
       "4         0.0              0.0         0.0             0.0         0.0   \n",
       "5         0.0              0.0         0.0             0.0         0.0   \n",
       "6         0.0              0.0         0.0             0.0         0.0   \n",
       "7         0.0              0.0         0.0             0.0         0.0   \n",
       "8         0.0              0.0         0.0             0.0         0.0   \n",
       "9         0.0              0.0         0.0             0.0         0.0   \n",
       "\n",
       "    count  25perc  50perc  75perc    max  \n",
       "0  6590.0    12.0    21.0    36.0  227.0  \n",
       "1  6590.0    12.0    21.0    36.0  227.0  \n",
       "2  6590.0    12.0    21.0    36.0  227.0  \n",
       "3  6590.0    12.0    21.0    36.0  227.0  \n",
       "4  6590.0    12.0    21.0    36.0  227.0  \n",
       "5  6590.0    12.0    21.0    36.0  227.0  \n",
       "6  6590.0    12.0    21.0    36.0  227.0  \n",
       "7  6590.0    12.0    21.0    36.0  227.0  \n",
       "8  6590.0    12.0    21.0    36.0  227.0  \n",
       "9  6590.0    12.0    21.0    36.0  227.0  \n",
       "\n",
       "[10 rows x 95 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constructing Dataset\n",
    "#del features\n",
    "#features = pd.DataFrame()\n",
    "features_2 = tfidf_of_features(sentences, words_common)\n",
    "# add words per sentence statistics\n",
    "stat_words_per_sentence(sentences, features_2)\n",
    "features_2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score : 0.7925801011804384\n",
      "Test set score : 0.7638620689655172\n"
     ]
    }
   ],
   "source": [
    "Y = features_2['text_source']\n",
    "X = features_2.drop(['text_source', 'text_sentence'], 1)\n",
    "\n",
    "# RandomForestModel\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,\n",
    "                                                    Y,\n",
    "                                                    test_size=0.55,\n",
    "                                                    random_state=4)\n",
    "rfc.fit(X_train, Y_train)\n",
    "\n",
    "print('Training set score : {}'.format(rfc.score(X_train, Y_train)))\n",
    "print('Test set score : {}'.format(rfc.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74663073, 0.77192982, 0.76923077, 0.76653171])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, X_train, Y_train, cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score : 0.7672849915682968\n",
      "Test set score : 0.7671724137931034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.74393531, 0.76248313, 0.76518219, 0.76923077])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "print('Training set score : {}'.format(lr.score(X_train, Y_train)))\n",
    "print('Test set score : {}'.format(lr.score(X_test, Y_test)))\n",
    "cross_val_score(lr, X_train, Y_train, cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:   Both models, Random forest or Logistic Regression,\n",
    "\n",
    "    give comparable results. Changing features method, from bag of word to tf idf, don't \n",
    "    make much differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
